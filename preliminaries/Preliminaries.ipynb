{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesser-commission",
   "metadata": {},
   "source": [
    "# Linear Regression from the Ground Up\n",
    "\n",
    "This notebook contains a direct implementation of linear regression using linear basis functions (polynomials).\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "The only libraries you should need for this notebook are `numpy`, `ipywidgets`, and `matplotlib`. You should be able to create the environment and run this notebook using comething like:\n",
    "\n",
    "    conda create -n FML matplotlib ipywidgets\n",
    "    conda activate FML\n",
    "    jupyter notebook LinearRegressionMLE.ipynb\n",
    "\n",
    "**Important**: If you are new to numerical programming in Python, I have also uploaded a VERY simple and VERY high-level tutorial of some of the numpy and Matplotlib features to the Moodle. There are many *excellent* tutorials out there.\n",
    "\n",
    "## Basic Setup\n",
    "\n",
    "We begin with a basic generative model (the one used in the introduction of the Bishop book). Scalar samples are generated from a sinusoidal function of the scalar input.\n",
    "\n",
    "We begin by importing some useful stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports for numerical programming.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-effect",
   "metadata": {},
   "source": [
    "Now we define the generative model in terms of a \"true\" function and an \"observed\" function corrupted with Gaussian noise with precision $\\beta$. We also define a utility function to apply a function (passed as an argument) to a uniform random sample of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The true function -- that is, what we want to estimate from data.\n",
    "def true_fn(x):\n",
    "    return np.sin(2*np.pi*x)\n",
    "\n",
    "# The observation process: true + Gaussian Noise.\n",
    "def observed_fn(x, beta=1.0):\n",
    "    return true_fn(x) + np.random.normal(0, np.sqrt(1/beta), size=x.shape)\n",
    "\n",
    "# How we actually observe a function: uniformly generate N random\n",
    "# xs in rng, apply the passed function to the xs.\n",
    "def sample_from_fn(fn, N, rng=[0.0, 1.0]):\n",
    "    xs = np.sort(np.random.random(size=(N,)) * (rng[1]-rng[0]) + rng[0])\n",
    "    return (xs, fn(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-panama",
   "metadata": {},
   "source": [
    "OK, let's play around with these functions. Visualization is our friend when trying to understand a problem from the ground up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 300 points from the true function and plot them (in green).\n",
    "(true_xs, true_fxs) = sample_from_fn(true_fn, 300)\n",
    "plt.plot(true_xs, true_fxs, 'g')\n",
    "\n",
    "# Now sample 20 points from the observed function and plot\n",
    "# the samples (in blue).\n",
    "(observed_xs, observed_fxs) = sample_from_fn(lambda x: observed_fn(x, beta=20), 20)\n",
    "plt.scatter(observed_xs, observed_fxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-providence",
   "metadata": {},
   "source": [
    "Note the **stochastic** nature of this process. Multiple executions of the sampling function will result in different realizations of the dataset.\n",
    "\n",
    "## Fitting a Model to Data\n",
    "\n",
    "We will now directly implement a *Regularized* least squares estimate of the optimal model parameters $\\mathbf{w}^*$.\n",
    "\n",
    "**Note**: this is not the Maximum Likelihood solution $\\mathbf{w}_{\\mbox{ML}}$ -- although if we select $\\lambda$ correctly we can recover it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the linear model with polynomial basis\n",
    "# and parameters w on inputs xs.\n",
    "def polynomial_model(xs, w):\n",
    "    Phi = np.vstack([[x**i for i in range(len(w))] for x in xs])\n",
    "    return np.squeeze(w[None, :] @ Phi.T)\n",
    "\n",
    "# This the direct estimate of w using the Moore-Penrose psuedo-inverse.\n",
    "# The order argument determines the order of the polynomial basis\n",
    "# embedding, and lam is the regularization coefficient.\n",
    "def regularized_least_squares(xs, ys, order, lam):\n",
    "    Phi = np.vstack([[x**i for i in range(order+1)] for x in xs])\n",
    "    w = np.linalg.inv(lam * np.eye(order+1) + Phi.T @ Phi) @ Phi.T @ ys\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-exemption",
   "metadata": {},
   "source": [
    "We can now solve for model parameters given the data in the current dataset (i.e. the last run of our generative process above). Let's solve for $\\mathbf{w}^*$ for a specific $\\lambda$ and order. Then we can plot the estimated solution (in red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate optimal model parameters.\n",
    "w_star = regularized_least_squares(observed_xs, observed_fxs, 10, 0.002)\n",
    "\n",
    "# Plot true function and observed samples.\n",
    "plt.scatter(observed_xs, observed_fxs)\n",
    "plt.plot(true_xs, true_fxs, 'g')\n",
    "\n",
    "# And plot our polynomial estimate.\n",
    "plt.plot(true_xs, polynomial_model(true_xs, w_star), 'r')\n",
    "plt.ylim([-1.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-distribution",
   "metadata": {},
   "source": [
    "## Putting it All Together\n",
    "\n",
    "Now we can implement a simple interactive widget that allows us to play with different polynomial orders and regularization coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# An interactive function that is called whenever the order or lambda\n",
    "# (actually parameterized as log-lambda) changes.\n",
    "@widgets.interact(order=(1, 100, 1), loglam=(-100.0, 0.0, 1.0))\n",
    "def plotter(order, loglam):\n",
    "    plt.figure(figsize=(13, 8))\n",
    "    w_star = regularized_least_squares(observed_xs, observed_fxs, order, np.exp(loglam))\n",
    "    plt.scatter(observed_xs, observed_fxs)\n",
    "    plt.plot(true_xs, true_fxs, 'g')\n",
    "    plt.plot(true_xs, polynomial_model(true_xs, w_star), 'r')\n",
    "    plt.ylim([-1.2, 1.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a454a2c-8ad8-4bb4-b8c7-4698f98b9523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
