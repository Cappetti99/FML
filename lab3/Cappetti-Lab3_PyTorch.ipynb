{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdf7099-a6d0-4b18-9216-f8e6701842f6",
   "metadata": {},
   "source": [
    "# Laboratory 3: Getting started with Pytorch\n",
    "\n",
    "In this laboratory we will begin working with Pytorch to implement and train complex, nonlinear models for supervised learning problems. You will notice many similarities between Numpy and Pytorch -- this is deliberate, but it can cause some confusion and for many things we will have to convert back and forth between Numpy arrays and Pytorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3117a44-c264-469e-91b6-2cc445413903",
   "metadata": {},
   "source": [
    "## Part 0: First steps\n",
    "\n",
    "**Important**: You **must** install Pytorch in your Anaconda environment for this laboratory. The easiest way to do this is to just install the CPU version of Pytorch like this:\n",
    "\n",
    "```\n",
    "conda activate FML\n",
    "conda install -c pytorch pytorch torchvision\n",
    "```\n",
    "\n",
    "**Note**: If you have an Nvidia GPU on your computer you can also install the GPU-enabled version of Pytorch which will **greatly** improve performance for more complex models and larger datasets. However, it can be very hard to get all of the versions of the required libraries to match correctly... During the laboratory we can look at it together if you are interested.\n",
    "\n",
    "After installing Pytorch, use the next cell to verify that the installation is working. If it prints a 3x3 sensor, we're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcdca90-bf99-4c35-b7e3-961f6ba45cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're still going to need numpy and matplotlib.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Verify that pytorch is working.\n",
    "import torch\n",
    "\n",
    "# If this works, things should be OK.\n",
    "print(torch.randn((3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f7466-0f8f-406e-a4e7-24e8a8135f8a",
   "metadata": {},
   "source": [
    "## Part 1: Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc2242-e79a-4e67-af09-8318126dde0e",
   "metadata": {},
   "source": [
    "We will work with the venerable MNIST dataset of handwritten digits in this laboratory. The `torchvision` library provides classes for a bunch of standard datasets, including MNIST. These classes automatically download and prepare the dataset for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0151f-9897-4fa0-8832-4603979427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the MNIST dataset.\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision\n",
    "\n",
    "# Load the MNIST training and test splits.\n",
    "ds_train = MNIST(root='./data', download=True, train=True)\n",
    "ds_test  = MNIST(root='./data', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2cf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_train)\n",
    "display(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7fc9b-2a69-48eb-bea1-9cf97117ebf8",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Exploratory data analysis\n",
    "\n",
    "Spend some time inspecting the `ds_train` and `ds_test` data structures in order to get a feel for the data. What is the format? How big are the images? How many are there? What about the range of pixel values? Where are the labels for images?\n",
    "\n",
    "Remember that one of the best ways to explore is to *visualize*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81157a27-3c60-432d-b3a0-6b6741f42747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some information about the dataset\n",
    "print(\"Number of training examples:\", len(ds_train))\n",
    "print(\"Number of test examples:\", len(ds_test))\n",
    "print(\"Image size:\", ds_train[0][0].size)\n",
    "\n",
    "# Plot a few sample images from the training set\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        image, label = ds_train[i * 5 + j]\n",
    "        axes[i, j].imshow(image, cmap='summer') #summer\n",
    "        axes[i, j].set_title(f\"Label: {label}\")\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e455494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random permutation of indices for the first 100 images in the training set\n",
    "random_indices = np.random.permutation(ds_train.data.shape[0])[:100]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Visualize the first 100 randomly selected images from the training set\n",
    "for i, index in enumerate(random_indices):\n",
    "    # Subplot organization: 10 rows, 10 columns, i+1 refers to the current subplot index\n",
    "    plt.subplot(10, 10, i+1)\n",
    "\n",
    "    # Display the image with random colormap\n",
    "    plt.imshow(ds_train.data[index], cmap=\"summer\")\n",
    "\n",
    "    \n",
    "    # Set the title with the corresponding label\n",
    "    plt.title(f\"Label: {ds_train.targets[index]}\")\n",
    "    \n",
    "    # Turn off axis ticks for cleaner visualization\n",
    "    plt.axis('off')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387e82e",
   "metadata": {},
   "source": [
    "commenta i colori\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f462b0-0bd1-4501-8b96-d34e8e873e8a",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Dataset conversion and normalization\n",
    "\n",
    "+ **Datatype Conversion**:\n",
    "The first thing we need to do is convert all data tensors to `torch.float32` -- this is fundamental as it is extremely inconvenient to work with `uint8` data. Using 32-bit floating point numbers is a compromise between precision and space efficiency.\n",
    "The `torch.Tensor` class has a very useful method `to()` for performing datatype and device (e.g. to GPU) conversions. Check out the [documentation here](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch-tensor-to).\n",
    "\n",
    "+ **Normalization**:\n",
    "Next, we need to correct the inconvenient range of [0, 255] for the pixel values. You should *subtract* the mean intensity value and divide by the standard deviation in order to *standardize* our data. **Important**: Think *very carefully* about *which* split you should use to compute the pixel statistics for standardization.\n",
    "\n",
    "+ **Reshaping**: Is the data in an appropriate format (i.e. shape) for the training the models we know? Think about whether (and how) to fix this if needed. \n",
    "\n",
    "**What to do**: In the cell below you should perform this sequence preprocessing operations on the `ds_train.data` and `ds_test.data` tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b71841-b3a6-4887-8c62-450aa4b36b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "import torch\n",
    "\n",
    "Xs_train = ds_train.data.to(torch.float32)\n",
    "ys_train = ds_train.targets\n",
    "Xs_test = ds_test.data.to(torch.float32)\n",
    "ys_test = ds_test.targets\n",
    "\n",
    "mean_px = Xs_train.mean()\n",
    "std_px = Xs_train.std()\n",
    "Xs_train = (Xs_train - mean_px) / std_px\n",
    "Xs_test = (Xs_test - mean_px) / std_px\n",
    "\n",
    "Xs_train.mean(), Xs_train.std(), Xs_test.mean(), Xs_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b930511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xs_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fcf34-8efe-4224-8138-8739d6c2c23f",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Subsampling the MNIST dataset.\n",
    "\n",
    "MNIST is kind of big, and thus inconvenient to work with unless using the GPU. For this laboratory we will use a smaller subset of the dataset for training to keep memory and computation times low.\n",
    "\n",
    "Modify `ds.train` to use only a subset of, say, 10000 images sampled from the original data. Make sure to select the correct corresponding targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2ea58-1f86-42fe-b867-f824e4966ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "train_size = 10000\n",
    "I = np.random.permutation(range(len(Xs_train)))[:train_size]\n",
    "Xs_train_i = Xs_train[I]\n",
    "ys_train_i = ys_train[I]\n",
    "\n",
    "Xs_train_i = Xs_train_i.flatten(start_dim=1)\n",
    "Xs_test_i = Xs_test.flatten(start_dim=1)\n",
    "\n",
    "Xs_train_i.shape, Xs_test_i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d557069-7f6d-4765-938f-6ff3e360b15d",
   "metadata": {},
   "source": [
    "## Establishing a stable baseline\n",
    "\n",
    "In this exercise you will establish a reliable baseline using a classical approach. This is an important step in our methodology in order to judge whether our Deep MLP is performing well or not.\n",
    "\n",
    "### Exercise 2.1: Establish the stable baseline\n",
    "\n",
    "Train and test your stable baseline to estimate the best achievable accuracy using classical models.\n",
    "\n",
    "**Tip**: Don't do any extensive cross-validation of your baseline (for now). Just fit a simple model (e.g. a linear SVM) and record the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8cf7-0632-46fa-b97e-32eef1f166ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "svc = LinearSVC(max_iter=max_iter)\n",
    "svc.fit(Xs_train_i, ys_train_i)\n",
    "\n",
    "preds = svc.predict(Xs_test_i)\n",
    "accuracy_score(ys_test.numpy(), preds)\n",
    "print(\"Accuracy: \", accuracy_score(ys_test, preds))\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(ys_test, svc.predict(Xs_test_i)))\n",
    "\n",
    "cm = confusion_matrix(ys_test, preds)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a93ac4",
   "metadata": {},
   "source": [
    "analisi del perchè mi venga un accuracy di 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Xs_test = Xs_test.flatten(-2)\n",
    "# Reshape the data if needed (SVC expects 2D input)\n",
    "Xs_train_2d = Xs_train_i.reshape(Xs_train_i.shape[0], -1)\n",
    "Xs_test_2d = Xs_test.reshape(Xs_test.shape[0], -1)\n",
    "\n",
    "# Instantiate the Support Vector Classifier (SVC)\n",
    "svc = SVC()\n",
    "\n",
    "# Fit the model on the training data\n",
    "svc.fit(Xs_train_2d, ys_train_i)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "predictions = svc.predict(Xs_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(ys_test.numpy(), svc.predict(Xs_test_2d))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(predictions, ys_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(ys_test, predictions)\n",
    "\n",
    "# Visualize the Confusion Matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6962c5f",
   "metadata": {},
   "source": [
    "commenta perchè questo è meglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ded91-0fc9-4923-883f-548adebbc4a1",
   "metadata": {},
   "source": [
    "## Part 3: Training some deep models (finally)\n",
    "\n",
    "Now we will finally train some deep models (Multilayer Perceptrons, to be precise). Since the dataset is a bit too large to use batch gradient descent, we will first need to setup a `torch.utils.data.DataLoader` for our training data. A `DataLoader` breaks the dataset up into a sequence of *batches* that will be used for training. In order to use this, we will first have to use `torch.utils.data.TensorDataset` on `ds_train.data` and `ds_train.targets` to make a new torch `dataset` for use in the dataloader. \n",
    "\n",
    "### Exercise 3.1: Creating the DataLoader\n",
    "\n",
    "Create a `DataLoader` for `ds_train` use a `batch_size` of about 16 or 32 to start. After you have your `DataLoader` experiment with is using `next(iter(dl_train))` to see what it returns. The pytorch `DataLoader` is a Python iterator.\n",
    "\n",
    "**EXTREMELY IMPORTANT**: Make sure you use `shuffle=True` in the constructor of your dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf280cd7-418f-4ed4-9ae8-4bb9a618e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "ds = TensorDataset(Xs_train_i, ys_train_i)\n",
    "dl_train = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "len(dl_train)\n",
    "\n",
    "batch = next(iter(dl_train))\n",
    "print(\"Feature shape:\", batch[0].shape)\n",
    "print(\"Target shape:\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c40712-538f-4efa-9752-f58a866d357f",
   "metadata": {},
   "source": [
    "### Some support code (NOT an exercise).\n",
    "\n",
    "Here is some support code that you can use to train a model for a **single** epoch. The function returns the mean loss over all iterations. You will use it in the next exercise to train and monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ed76b-b385-46d2-904e-f2ee31b9a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model for a single epoch. You should pass it a model, a dataloader,\n",
    "# and an optimizer. Returns the mean loss over the entire epoch.\n",
    "def train_epoch(model, dl, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for (xs, ys) in dl:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xs)\n",
    "        loss = torch.nn.functional.nll_loss(output, ys) #compute the negative log likelihood loss\n",
    "        loss.backward() #compute the gradient \n",
    "        optimizer.step() #tell the optimizer to perform a gradient step\n",
    "        losses.append(loss.item())\n",
    "    model.eval()\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaaaf4a-7266-43b8-a5b6-c36c7cb087bc",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Defining a 1-layer neural network\n",
    "\n",
    "Define a simple model that uses a **single** `torch.nn.Linear` layer followed by a `torch.nn.Softmax` to predict  the output probabilities for the ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f6ae8-5826-44ab-9077-6358f7585f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fresh model.\n",
    "import torch.nn as nn\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    # Your code here.\n",
    "    nn.Linear(784, 10),\n",
    "    nn.LogSoftmax(dim=1)   # Specify dim=1 to apply LogSoftmax along the second dimension\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892210c-7b7c-4bab-a648-121d52190cb1",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Training our model\n",
    "\n",
    "Instantiate a `torch.optim.SGD` optimizer using `model.parameters()` and the learning rate (**tip**: make the learning rate a variable you can easily change). Then run `train_epoch` for a set number of epochs (e.g. 100, make this a variable too). Is your model learning? How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca7a8f-f7a9-4536-a4ba-51ab0e9fbead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    # Your code here.\n",
    "    nn.Linear(784, 10),\n",
    "    nn.LogSoftmax(dim=1)   \n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "lr = 1e-2   # Learning rate\n",
    "losses = []\n",
    "opt = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "#Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss = train_epoch(model, dl_train, opt)\n",
    "    losses.append(train_epoch(model, dl_train, opt))\n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(ys_test, model(Xs_test_i).argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2209ce-48d6-4412-9973-456c2d0ae1f0",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Evaluating our model\n",
    "\n",
    "Write some code to plot the loss curve for your training run and evaluate the performance of your model on the test data. Play with the hyperparameters (e.g. learning rate) to try to get the best performance on the test set. Can you beat the stable baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cbde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Funzione per calcolare l'accuratezza\n",
    "def compute_accuracy(model, X, y):\n",
    "    predictions = torch.argmax(model(X), dim=1)\n",
    "    return (predictions == y).float().mean().item()\n",
    "\n",
    "# Funzione per allenare il modello con una combinazione di iperparametri\n",
    "def train_with_hyperparameters(model, optimizer, data_loader, num_epochs):\n",
    "    train_loss_curve = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, data_loader, optimizer)\n",
    "        train_loss_curve.append(train_loss)\n",
    "    return train_loss_curve\n",
    "\n",
    "# Funzione principale per allenare e valutare il modello\n",
    "def train_and_evaluate(model, learning_rate, batch_size, num_epochs):\n",
    "    # Configurazione iperparametri\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(Xs_train_2d, ys_train_i),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Allenamento\n",
    "    train_loss_curve = train_with_hyperparameters(model, optimizer, train_loader, num_epochs)\n",
    "\n",
    "    # Valutazione sul test set\n",
    "    test_accuracy = compute_accuracy(model, Xs_test_2d, ys_test)\n",
    "\n",
    "    return train_loss_curve, test_accuracy\n",
    "\n",
    "# Funzione per tracciare la curva di perdita\n",
    "def plot_loss_curve(train_loss_curve, learning_rate, batch_size):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_loss_curve, label=f\"LR: {learning_rate}, Batch: {batch_size}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def reset_parameters(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "# Iperparametri iniziali\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [16, 64, 256]\n",
    "num_epochs = 100\n",
    "\n",
    "# Baseline per confronto\n",
    "accuracy_score_linearSVC = 0.88  # Accuracy ottenuta con LinearSVC\n",
    "accuracy_score_nl_SVC = 0.96  # Supponendo un baseline di accuratezza\n",
    "\n",
    "# Ricerca del miglior modello\n",
    "best_accuracy = 0.0\n",
    "best_hyperparameters = {}\n",
    "best_loss_curve = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"Training with LR: {lr}, Batch Size: {batch_size}\")\n",
    "        model.apply(reset_parameters)  # Resetta i pesi del modello per ogni nuova combinazione\n",
    "        loss_curve, test_accuracy = train_and_evaluate(model, lr, batch_size, num_epochs)\n",
    "\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_hyperparameters = {'learning_rate': lr, 'batch_size': batch_size}\n",
    "            best_loss_curve = loss_curve\n",
    "\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Traccia la curva di perdita del miglior modello\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Learning Rate: {best_hyperparameters['learning_rate']}, Batch Size: {best_hyperparameters['batch_size']}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "if(best_accuracy > accuracy_score_nl_SVC):\n",
    "    print(\"The model is better than the Non-Linear SVC baseline and the Linear SVC baseline\")\n",
    "else:\n",
    "    if(best_accuracy > accuracy_score_linearSVC):\n",
    "        print(\"The model is better than the Linear SVC baseline\")\n",
    "    else:\n",
    "        print(\"The model is worse than both baselines\")\n",
    "\n",
    "plot_loss_curve(best_loss_curve, best_hyperparameters['learning_rate'], best_hyperparameters['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7842b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e688ba-cc3f-4445-ab6b-6675a446ba1c",
   "metadata": {},
   "source": [
    "## Going Deeper\n",
    "\n",
    "Now we will go (at least one layer) deeper to see if we can significantly improve on the baseline.\n",
    "\n",
    "### Exercise 3.4: A 2-layer MLP\n",
    "Define a new model with one hidden layer. Use the code you wrote above to train and evaluate this new model. Can you beat the baseline? You might need to train in two stages using different learning rates.\n",
    "\n",
    "**Things to think about**:\n",
    "\n",
    "+ It might be hard to beat (or even equal) the baseline with deeper networks. Why?\n",
    "+ Is there something else we should be monitoring while training, especially for deep networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c9686-49d7-4bc3-bbd9-0671547bd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie necessarie\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Dimensione dello strato nascosto\n",
    "inner_size = 256\n",
    "\n",
    "# Definizione del modello MLP con un livello nascosto\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(784, inner_size),  # Primo livello lineare\n",
    "    nn.ReLU(),                   # Funzione di attivazione ReLU\n",
    "    nn.Linear(inner_size, 10),   # Secondo livello lineare (uscita)\n",
    "    nn.LogSoftmax(dim=1)         # Softmax per classificazione logaritmica\n",
    ")\n",
    "\n",
    "# Parametri di configurazione\n",
    "epochs = 1000  # Numero di epoche\n",
    "lr = 1e-3     # Learning rate\n",
    "losses = []   # Per tracciare l'andamento della perdita\n",
    "\n",
    "# Ottimizzatore e funzione di perdita\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr)  # Stochastic Gradient Descent\n",
    "criterion = nn.NLLLoss()  # Negative Log Likelihood Loss per classificazione\n",
    "\n",
    "# Ciclo di addestramento\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()  # Modalità di addestramento\n",
    "    total_loss = 0  # Inizializzazione della perdita totale\n",
    "    \n",
    "    for X_batch, y_batch in dl_train:  # dl_train è il dataloader di training\n",
    "        opt.zero_grad()  # Reset dei gradienti\n",
    "        output = model(X_batch)  # Forward pass\n",
    "        loss = criterion(output, y_batch)  # Calcolo della perdita\n",
    "        loss.backward()  # Backpropagation\n",
    "        opt.step()  # Aggiornamento dei pesi\n",
    "        total_loss += loss.item()  # Accumula la perdita\n",
    "    \n",
    "    # Salva la perdita media per ogni epoca\n",
    "    losses.append(total_loss / len(dl_train))\n",
    "\n",
    "# Grafico della perdita durante l'addestramento\n",
    "plt.plot(losses)\n",
    "plt.title('Loss Trend During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Valutazione sul test set\n",
    "model.eval()  # Modalità di valutazione\n",
    "with torch.no_grad():  # Disabilita il calcolo dei gradienti\n",
    "    preds = torch.argmax(model(Xs_test_i), dim=1)  # Predizioni\n",
    "    print(classification_report(ys_test, preds))  # Report di classificazione"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7c1cf1bb",
   "metadata": {},
   "source": [
    "100%|██████████| 1000/1000 [05:22<00:00,  3.10it/s]\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.98      0.97       980\n",
    "           1       0.98      0.99      0.98      1135\n",
    "           2       0.95      0.96      0.95      1032\n",
    "           3       0.95      0.96      0.95      1010\n",
    "           4       0.95      0.96      0.96       982\n",
    "           5       0.95      0.94      0.95       892\n",
    "           6       0.95      0.96      0.95       958\n",
    "           7       0.95      0.95      0.95      1028\n",
    "           8       0.96      0.94      0.95       974\n",
    "           9       0.95      0.93      0.94      1009\n",
    "\n",
    "    accuracy                           0.96     10000\n",
    "   macro avg       0.96      0.96      0.96     10000\n",
    "weighted avg       0.96      0.96      0.96     10000\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
