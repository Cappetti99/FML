{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdf7099-a6d0-4b18-9216-f8e6701842f6",
   "metadata": {},
   "source": [
    "# Laboratory 3: Getting started with Pytorch\n",
    "\n",
    "In this laboratory we will begin working with Pytorch to implement and train complex, nonlinear models for supervised learning problems. You will notice many similarities between Numpy and Pytorch -- this is deliberate, but it can cause some confusion and for many things we will have to convert back and forth between Numpy arrays and Pytorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3117a44-c264-469e-91b6-2cc445413903",
   "metadata": {},
   "source": [
    "## Part 0: First steps\n",
    "\n",
    "**Important**: You **must** install Pytorch in your Anaconda environment for this laboratory. The easiest way to do this is to just install the CPU version of Pytorch like this:\n",
    "\n",
    "```\n",
    "conda activate FML\n",
    "conda install -c pytorch pytorch torchvision\n",
    "```\n",
    "\n",
    "**Note**: If you have an Nvidia GPU on your computer you can also install the GPU-enabled version of Pytorch which will **greatly** improve performance for more complex models and larger datasets. However, it can be very hard to get all of the versions of the required libraries to match correctly... During the laboratory we can look at it together if you are interested.\n",
    "\n",
    "After installing Pytorch, use the next cell to verify that the installation is working. If it prints a 3x3 sensor, we're good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcdca90-bf99-4c35-b7e3-961f6ba45cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're still going to need numpy and matplotlib.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Verify that pytorch is working.\n",
    "import torch\n",
    "\n",
    "# If this works, things should be OK.\n",
    "print(torch.randn((3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f7466-0f8f-406e-a4e7-24e8a8135f8a",
   "metadata": {},
   "source": [
    "## Part 1: Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc2242-e79a-4e67-af09-8318126dde0e",
   "metadata": {},
   "source": [
    "We will work with the venerable MNIST dataset of handwritten digits in this laboratory. The `torchvision` library provides classes for a bunch of standard datasets, including MNIST. These classes automatically download and prepare the dataset for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0151f-9897-4fa0-8832-4603979427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the MNIST dataset.\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision\n",
    "\n",
    "# Load the MNIST training and test splits.\n",
    "ds_train = MNIST(root='./data', download=True, train=True)\n",
    "ds_test  = MNIST(root='./data', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2cf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_train)\n",
    "display(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ecd66",
   "metadata": {},
   "source": [
    "**Analisys:** The dataset is automatically split into train and test, assigning 60,000 datapoints to the train set and 10,000 to the test set. This is predefined by the dataset, so in the code, you only need to specify whether `train = True` or `train = False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7fc9b-2a69-48eb-bea1-9cf97117ebf8",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Exploratory data analysis\n",
    "\n",
    "Spend some time inspecting the `ds_train` and `ds_test` data structures in order to get a feel for the data. What is the format? How big are the images? How many are there? What about the range of pixel values? Where are the labels for images?\n",
    "\n",
    "Remember that one of the best ways to explore is to *visualize*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81157a27-3c60-432d-b3a0-6b6741f42747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some information about the dataset\n",
    "print(\"Number of training examples:\", len(ds_train))\n",
    "print(\"Number of test examples:\", len(ds_test))\n",
    "print(\"Image size:\", ds_train[0][0].size)\n",
    "\n",
    "# Plot a few sample images from the training set\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        image, label = ds_train[i * 5 + j]\n",
    "        axes[i, j].imshow(image, cmap='summer') #summer\n",
    "        axes[i, j].set_title(f\"Label: {label}\")\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e455494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random permutation of indices for the first 100 images in the training set\n",
    "random_indices = np.random.permutation(ds_train.data.shape[0])[:100]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Visualize the first 100 randomly selected images from the training set\n",
    "for i, index in enumerate(random_indices):\n",
    "    # Subplot organization: 10 rows, 10 columns, i+1 refers to the current subplot index\n",
    "    plt.subplot(10, 10, i+1)\n",
    "\n",
    "    # Display the image with random colormap\n",
    "    plt.imshow(ds_train.data[index], cmap=\"summer\")\n",
    "\n",
    "    \n",
    "    # Set the title with the corresponding label\n",
    "    plt.title(f\"Label: {ds_train.targets[index]}\")\n",
    "    \n",
    "    # Turn off axis ticks for cleaner visualization\n",
    "    plt.axis('off')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the visualization\n",
    "plt.show()\n",
    "\n",
    "#MINIST dataset\n",
    "#https://paperswithcode.com/dataset/mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387e82e",
   "metadata": {},
   "source": [
    "**Analisys:** The MNIST database (Modified National Institute of Standards and Technology database) is a large collection of handwritten digits. It has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger NIST Special Database 3 (digits written by employees of the United States Census Bureau) and Special Database 1 (digits written by high school students) which contain monochrome images of handwritten digits. The digits have been size-normalized and centered in a fixed-size image. \n",
    "\n",
    "\n",
    "https://paperswithcode.com/dataset/mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f462b0-0bd1-4501-8b96-d34e8e873e8a",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Dataset conversion and normalization\n",
    "\n",
    "+ **Datatype Conversion**:\n",
    "The first thing we need to do is convert all data tensors to `torch.float32` -- this is fundamental as it is extremely inconvenient to work with `uint8` data. Using 32-bit floating point numbers is a compromise between precision and space efficiency.\n",
    "The `torch.Tensor` class has a very useful method `to()` for performing datatype and device (e.g. to GPU) conversions. Check out the [documentation here](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch-tensor-to).\n",
    "\n",
    "+ **Normalization**:\n",
    "Next, we need to correct the inconvenient range of [0, 255] for the pixel values. You should *subtract* the mean intensity value and divide by the standard deviation in order to *standardize* our data. **Important**: Think *very carefully* about *which* split you should use to compute the pixel statistics for standardization.\n",
    "\n",
    "+ **Reshaping**: Is the data in an appropriate format (i.e. shape) for the training the models we know? Think about whether (and how) to fix this if needed. \n",
    "\n",
    "**What to do**: In the cell below you should perform this sequence preprocessing operations on the `ds_train.data` and `ds_test.data` tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b71841-b3a6-4887-8c62-450aa4b36b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Conversione dei dati di addestramento in tensori float32\n",
    "Xs_train = ds_train.data.to(torch.float32)\n",
    "ys_train = ds_train.targets  # Target di addestramento (etichette)\n",
    "Xs_test = ds_test.data.to(torch.float32)\n",
    "ys_test = ds_test.targets  # Target di test (etichette)\n",
    "\n",
    "# Calcolo della media e della deviazione standard dell'insieme di addestramento\n",
    "mean_px = Xs_train.mean()\n",
    "std_px = Xs_train.std()\n",
    "\n",
    "# Normalizzazione: sottrazione della media e divisione per la deviazione standard\n",
    "Xs_train = (Xs_train - mean_px) / std_px\n",
    "Xs_test = (Xs_test - mean_px) / std_px  # Normalizzazione coerente rispetto ai dati di addestramento\n",
    "\n",
    "# Controllo delle statistiche dopo la normalizzazione\n",
    "Xs_train.mean(), Xs_train.std(), Xs_test.mean(), Xs_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test.flatten(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b930511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xs_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3a58a",
   "metadata": {},
   "source": [
    "**Analisys:** The data in ds_train.data and ds_test.data is converted to float32. This is important because many machine learning operations require data in floating-point format.\n",
    "The mean (mean_px) and standard deviation (std_px) are calculated on the training data (Xs_train). These values will be used for normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fcf34-8efe-4224-8138-8739d6c2c23f",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Subsampling the MNIST dataset.\n",
    "\n",
    "MNIST is kind of big, and thus inconvenient to work with unless using the GPU. For this laboratory we will use a smaller subset of the dataset for training to keep memory and computation times low.\n",
    "\n",
    "Modify `ds.train` to use only a subset of, say, 10000 images sampled from the original data. Make sure to select the correct corresponding targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2ea58-1f86-42fe-b867-f824e4966ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "train_size = 10000\n",
    "I = np.random.permutation(range(len(Xs_train)))[:train_size]\n",
    "Xs_train_i = Xs_train[I]\n",
    "ys_train_i = ys_train[I]\n",
    "\n",
    "Xs_train_i = Xs_train_i.flatten(start_dim=1)\n",
    "Xs_test_i = Xs_test.flatten(start_dim=1)\n",
    "\n",
    "Xs_train_i.shape, Xs_test_i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ec20d",
   "metadata": {},
   "source": [
    "**Analisys:** I reduced the dataset to 10000, so it’s lighter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d557069-7f6d-4765-938f-6ff3e360b15d",
   "metadata": {},
   "source": [
    "## Establishing a stable baseline\n",
    "\n",
    "In this exercise you will establish a reliable baseline using a classical approach. This is an important step in our methodology in order to judge whether our Deep MLP is performing well or not.\n",
    "\n",
    "### Exercise 2.1: Establish the stable baseline\n",
    "\n",
    "Train and test your stable baseline to estimate the best achievable accuracy using classical models.\n",
    "\n",
    "**Tip**: Don't do any extensive cross-validation of your baseline (for now). Just fit a simple model (e.g. a linear SVM) and record the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8cf7-0632-46fa-b97e-32eef1f166ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parametro massimo di iterazioni per LinearSVC\n",
    "max_iter = 1000\n",
    "\n",
    "# Addestramento del modello\n",
    "svc = LinearSVC(max_iter=max_iter)\n",
    "svc.fit(Xs_train_i, ys_train_i)\n",
    "\n",
    "# Predizione sui dati di test\n",
    "preds = svc.predict(Xs_test_i)\n",
    "\n",
    "# Calcolo dell'accuratezza\n",
    "accuracy = accuracy_score(ys_test, preds)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Report di classificazione\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(ys_test, preds))\n",
    "\n",
    "# Matrice di confusione non normalizzata\n",
    "cm = confusion_matrix(ys_test, preds)\n",
    "\n",
    "# Visualizzazione della matrice di confusione non normalizzata\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix (Not Normalized)')\n",
    "plt.show()\n",
    "\n",
    "# Normalizzazione della matrice di confusione (lungo le righe)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Visualizzazione della matrice di confusione normalizzata\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix (Normalized)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41704cd3",
   "metadata": {},
   "source": [
    "**Analisys:**  The results from the analysis of the LinearSVC model show an overall accuracy of 87.4%, which is positive but suggests there is still room for improvement, especially for certain specific classes.\n",
    "\n",
    "From the classification report, it appears that the model performs well for some classes, such as 0 and 1, which achieve precision and recall above 92%. These figures indicate that the model can clearly distinguish these categories. However, there are problematic classes, like 5, which records the lowest F1-score (0.81), followed by 8 (F1-score: 0.79). These values suggest that the model struggles to differentiate these digits from others, likely due to overlaps in the data features.\n",
    "\n",
    "Looking at the confusion matrix, it is evident that class 5 is frequently confused with class 3 and class 8, while samples from class 8 are often predicted as belonging to classes 5 or 9. These errors indicate that the model has difficulty correctly separating visually or numerically similar classes.\n",
    "\n",
    "Moving to the normalized version of the confusion matrix, we see that classes like 0, 1, 6, and 7 have a very high recall, confirming that the model is particularly reliable at recognizing these categories. In contrast, classes 2, 5, and 8 have lower recall, indicating greater confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Xs_test = Xs_test.flatten(-2)\n",
    "# Reshape the data if needed (SVC expects 2D input)\n",
    "Xs_train_2d = Xs_train_i.reshape(Xs_train_i.shape[0], -1)\n",
    "Xs_test_2d = Xs_test.reshape(Xs_test.shape[0], -1)\n",
    "\n",
    "# Instantiate the Support Vector Classifier (SVC)\n",
    "svc = SVC()\n",
    "\n",
    "# Fit the model on the training data\n",
    "svc.fit(Xs_train_2d, ys_train_i)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "predictions = svc.predict(Xs_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(ys_test.numpy(), svc.predict(Xs_test_2d))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(predictions, ys_test))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(ys_test, predictions)\n",
    "\n",
    "# Visualize the Confusion Matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Normalizzazione della matrice di confusione (lungo le righe)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Visualizzazione della matrice di confusione normalizzata\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix (Normalized)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6962c5f",
   "metadata": {},
   "source": [
    "**Analisys:** The results obtained from the analysis of the SVC model with the default kernel (probably RBF) show an overall accuracy of 96.34%, a very high value that reflects the model’s ability to correctly distinguish most classes. This result is significantly better than linear models like LinearSVC, suggesting that the choice of a more sophisticated model had a positive impact.\n",
    "\n",
    "From the classification report, it is evident that the model performs excellently for many classes, particularly for classes 0, 1, and 6, which achieve precision and recall above 97%. This indicates that the model recognizes these digits with great accuracy. However, some classes, such as 8 and 9, show slightly lower F1-scores (0.95 and 0.95, respectively), indicating that the model has some difficulty distinguishing them.\n",
    "\n",
    "Analyzing the confusion matrix, we see that the main errors occur in classes 5, 8, and 9. For example, class 5 is sometimes confused with class 3 or 8, while class 9 is occasionally predicted as 4 or 7. These errors reflect some visual overlap between the digits, especially for samples that are written similarly or have common characteristics.\n",
    "\n",
    "The normalized confusion matrix provides a clearer view of the proportions of errors. Classes such as 0, 1, 6, and 7 show very high recall, approaching 99%, demonstrating that the model recognizes them almost perfectly. In contrast, classes 5, 8, and 9 have slightly lower recall, around 93-95%, highlighting that the model encounters some difficulties in more ambiguous situations.\n",
    "\n",
    "These results indicate the strength of the SVC model, which, thanks to the nonlinear kernel, is capable of capturing complex relationships between the features of the data. However, for more difficult classes like 5 and 9, it might be useful to explore alternative approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ded91-0fc9-4923-883f-548adebbc4a1",
   "metadata": {},
   "source": [
    "## Part 3: Training some deep models (finally)\n",
    "\n",
    "Now we will finally train some deep models (Multilayer Perceptrons, to be precise). Since the dataset is a bit too large to use batch gradient descent, we will first need to setup a `torch.utils.data.DataLoader` for our training data. A `DataLoader` breaks the dataset up into a sequence of *batches* that will be used for training. In order to use this, we will first have to use `torch.utils.data.TensorDataset` on `ds_train.data` and `ds_train.targets` to make a new torch `dataset` for use in the dataloader. \n",
    "\n",
    "### Exercise 3.1: Creating the DataLoader\n",
    "\n",
    "Create a `DataLoader` for `ds_train` use a `batch_size` of about 16 or 32 to start. After you have your `DataLoader` experiment with is using `next(iter(dl_train))` to see what it returns. The pytorch `DataLoader` is a Python iterator.\n",
    "\n",
    "**EXTREMELY IMPORTANT**: Make sure you use `shuffle=True` in the constructor of your dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf280cd7-418f-4ed4-9ae8-4bb9a618e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "ds = TensorDataset(Xs_train_i, ys_train_i)\n",
    "dl_train = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "len(dl_train)\n",
    "\n",
    "batch = next(iter(dl_train))\n",
    "print(\"Feature shape:\", batch[0].shape)\n",
    "print(\"Target shape:\", batch[1].shape)\n",
    "\n",
    "# Pytorch example\n",
    "#https://github.com/pytorch/examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c40712-538f-4efa-9752-f58a866d357f",
   "metadata": {},
   "source": [
    "### Some support code (NOT an exercise).\n",
    "\n",
    "Here is some support code that you can use to train a model for a **single** epoch. The function returns the mean loss over all iterations. You will use it in the next exercise to train and monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ed76b-b385-46d2-904e-f2ee31b9a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model for a single epoch. You should pass it a model, a dataloader,\n",
    "# and an optimizer. Returns the mean loss over the entire epoch.\n",
    "def train_epoch(model, dl, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for (xs, ys) in dl:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xs)\n",
    "        loss = torch.nn.functional.nll_loss(output, ys) #compute the negative log likelihood loss\n",
    "        loss.backward() #compute the gradient \n",
    "        optimizer.step() #tell the optimizer to perform a gradient step\n",
    "        losses.append(loss.item())\n",
    "    model.eval()\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b91659",
   "metadata": {},
   "source": [
    "**Analisys:** model.train() and model.eval():\n",
    "model.train() sets the model to training mode, and model.eval() sets it to evaluation mode. This is important because certain layers (e.g., dropout) behave differently during training and evaluation. In training mode, dropout is active, but in evaluation mode, it's turned off.\n",
    "\n",
    "optimizer.zero_grad():\n",
    "Before computing the gradients for the parameters, the optimizer's zero_grad() method is called to clear the previously calculated gradients. This is necessary because PyTorch accumulates gradients by default.\n",
    "\n",
    "Forward Pass (output = model(xs)):\n",
    "The input batch (xs) is passed through the model to obtain predictions (output). This is the forward pass.\n",
    "\n",
    "Loss Computation (loss = torch.nn.functional.nll_loss(output, ys)):\n",
    "The negative log likelihood loss is computed using the model's predictions (output) and the ground truth labels (ys).\n",
    "\n",
    "Backward Pass (loss.backward()):\n",
    "Gradients are computed for all model parameters with respect to the loss using the backward() method.\n",
    "\n",
    "Gradient Descent Step (optimizer.step()):\n",
    "The optimizer's step() method is called to perform a step of gradient descent, updating the model parameters based on the computed gradients.\n",
    "\n",
    "Record the Loss (losses.append(loss.item())):\n",
    "The loss for the current iteration is recorded in the losses list.\n",
    "\n",
    "Return the Mean Loss (return np.mean(losses)):\n",
    "The function returns the mean loss over all iterations in the epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaaaf4a-7266-43b8-a5b6-c36c7cb087bc",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Defining a 1-layer neural network\n",
    "\n",
    "Define a simple model that uses a **single** `torch.nn.Linear` layer followed by a `torch.nn.Softmax` to predict  the output probabilities for the ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f6ae8-5826-44ab-9077-6358f7585f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fresh model.\n",
    "import torch.nn as nn\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    # Your code here.\n",
    "    nn.Linear(784, 10),\n",
    "    nn.LogSoftmax(dim=1)   # Specify dim=1 to apply LogSoftmax along the second dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e46ce6",
   "metadata": {},
   "source": [
    "**Analisys:** `torch.nn.Linear`: This is a linear transformation layer in PyTorch. It represents an affine transformation, which is a linear transformation with a bias term. Mathematically, it performs the operation y = xA^T + b, where x is the input tensor, A is the weight matrix, b is the bias vector, and y is the output tensor.\n",
    "\n",
    "`torch.nn.LogSoftmax`: This layer applies the logarithm of the softmax function to the output of the linear layer. It converts raw scores (logits) into log probabilities, which are numerically more stable for classification tasks. The dim=1 argument specifies that the operation is performed along the second dimension (class scores for each input sample in a batch).\n",
    "\n",
    "\n",
    "https://pytorch.org/docs/\n",
    "\n",
    "https://pytorch.org/vision/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892210c-7b7c-4bab-a648-121d52190cb1",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Training our model\n",
    "\n",
    "Instantiate a `torch.optim.SGD` optimizer using `model.parameters()` and the learning rate (**tip**: make the learning rate a variable you can easily change). Then run `train_epoch` for a set number of epochs (e.g. 100, make this a variable too). Is your model learning? How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca7a8f-f7a9-4536-a4ba-51ab0e9fbead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    # Your code here.\n",
    "    nn.Linear(784, 10),\n",
    "    nn.LogSoftmax(dim=1)   \n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "lr = 1e-2   # Learning rate\n",
    "losses = []\n",
    "opt = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "#Training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss = train_epoch(model, dl_train, opt)\n",
    "    losses.append(train_epoch(model, dl_train, opt))\n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(ys_test, model(Xs_test_i).argmax(dim=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a07dce",
   "metadata": {},
   "source": [
    "**Analisys:** The loss curve and the classification report provide a clear overview of the model’s performance and the training process.\n",
    "\n",
    "`Loss Curve`\n",
    "\n",
    "The training loss curve shows a typical behavior of a model that is learning correctly. Initially, the loss decreases rapidly, indicating that the model is learning the fundamental features from the data. As the epochs progress, the rate of decrease slows down, and the curve stabilizes, indicating that the model is reaching convergence. This is a good sign, as it suggests that the model has been trained sufficiently and shows no clear signs of overfitting or underfitting.\n",
    "\n",
    "`Classification Report`\n",
    "\n",
    "Looking at the results, the overall accuracy is 91%, which is a good value.\n",
    "Strengths: Classes 0, 1, 6, and 7 show very high precision and recall, close to 95%-96%. This indicates that the model can effectively distinguish these categories.\n",
    "\n",
    "Classes 3, 5, and 8, however, have slightly lower F1-scores (between 85% and 88%). This may suggest that the model finds it more difficult to distinguish these classes, likely due to less obvious features or overlap in the input data.\n",
    "\n",
    "The global averages (macro avg and weighted avg) confirm that the model maintains solid performance overall, with no significant imbalance between the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2209ce-48d6-4412-9973-456c2d0ae1f0",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Evaluating our model\n",
    "\n",
    "Write some code to plot the loss curve for your training run and evaluate the performance of your model on the test data. Play with the hyperparameters (e.g. learning rate) to try to get the best performance on the test set. Can you beat the stable baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cbde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Funzione per calcolare l'accuratezza\n",
    "def compute_accuracy(model, X, y):\n",
    "    predictions = torch.argmax(model(X), dim=1)\n",
    "    return (predictions == y).float().mean().item()\n",
    "\n",
    "# Funzione per allenare il modello con una combinazione di iperparametri\n",
    "def train_with_hyperparameters(model, optimizer, data_loader, num_epochs):\n",
    "    train_loss_curve = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, data_loader, optimizer)\n",
    "        train_loss_curve.append(train_loss)\n",
    "    return train_loss_curve\n",
    "\n",
    "# Funzione principale per allenare e valutare il modello\n",
    "def train_and_evaluate(model, learning_rate, batch_size, num_epochs):\n",
    "    # Configurazione iperparametri\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(Xs_train_2d, ys_train_i),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Allenamento\n",
    "    train_loss_curve = train_with_hyperparameters(model, optimizer, train_loader, num_epochs)\n",
    "\n",
    "    # Valutazione sul test set\n",
    "    test_accuracy = compute_accuracy(model, Xs_test_2d, ys_test)\n",
    "\n",
    "    return train_loss_curve, test_accuracy\n",
    "\n",
    "# Funzione per tracciare la curva di perdita\n",
    "def plot_loss_curve(train_loss_curve, learning_rate, batch_size):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_loss_curve, label=f\"LR: {learning_rate}, Batch: {batch_size}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def reset_parameters(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "# Iperparametri iniziali\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "batch_sizes = [16, 64, 256]\n",
    "num_epochs = 100\n",
    "\n",
    "# Baseline per confronto\n",
    "accuracy_score_linearSVC = 0.88  # Accuracy ottenuta con LinearSVC\n",
    "accuracy_score_nl_SVC = 0.96  # Supponendo un baseline di accuratezza\n",
    "\n",
    "# Ricerca del miglior modello\n",
    "best_accuracy = 0.0\n",
    "best_hyperparameters = {}\n",
    "best_loss_curve = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"Training with LR: {lr}, Batch Size: {batch_size}\")\n",
    "        model.apply(reset_parameters)  # Resetta i pesi del modello per ogni nuova combinazione\n",
    "        loss_curve, test_accuracy = train_and_evaluate(model, lr, batch_size, num_epochs)\n",
    "\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_hyperparameters = {'learning_rate': lr, 'batch_size': batch_size}\n",
    "            best_loss_curve = loss_curve\n",
    "\n",
    "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Traccia la curva di perdita del miglior modello\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Learning Rate: {best_hyperparameters['learning_rate']}, Batch Size: {best_hyperparameters['batch_size']}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "if(best_accuracy > accuracy_score_nl_SVC):\n",
    "    print(\"The model is better than the Non-Linear SVC baseline and the Linear SVC baseline\")\n",
    "else:\n",
    "    if(best_accuracy > accuracy_score_linearSVC):\n",
    "        print(\"The model is better than the Linear SVC baseline\")\n",
    "    else:\n",
    "        print(\"The model is worse than both baselines\")\n",
    "\n",
    "plot_loss_curve(best_loss_curve, best_hyperparameters['learning_rate'], best_hyperparameters['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7842b3",
   "metadata": {},
   "source": [
    "**Analisys:** A higher learning rate (0.001 and 0.01) tends to lead to better accuracy compared to 0.0001. This is normal because values that are too low can slow down convergence or cause the model to get stuck in a suboptimal local minimum.\n",
    "\n",
    "The batch size impacts performance. With smaller batches (e.g., 16), there is a slight tendency toward better generalization. This is probably due to the increased variability introduced by smaller batches, which helps to better explore the solution space.\n",
    "\n",
    "The model performs well with a higher learning rate and larger batches, suggesting a good ability to learn from larger datasets without overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e688ba-cc3f-4445-ab6b-6675a446ba1c",
   "metadata": {},
   "source": [
    "## Going Deeper\n",
    "\n",
    "Now we will go (at least one layer) deeper to see if we can significantly improve on the baseline.\n",
    "\n",
    "### Exercise 3.4: A 2-layer MLP\n",
    "Define a new model with one hidden layer. Use the code you wrote above to train and evaluate this new model. Can you beat the baseline? You might need to train in two stages using different learning rates.\n",
    "\n",
    "**Things to think about**:\n",
    "\n",
    "+ It might be hard to beat (or even equal) the baseline with deeper networks. Why?\n",
    "+ Is there something else we should be monitoring while training, especially for deep networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c9686-49d7-4bc3-bbd9-0671547bd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a 2-layer MLP\n",
    "class MLP2Layer(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP2Layer, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "# Function to plot training curves\n",
    "def plot_training_curves(loss_curve, accuracy_curve, title):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Training Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(loss_curve, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Loss Curve ({title})')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Training Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(accuracy_curve, label='Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Training Accuracy Curve ({title})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to train the model for one epoch\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Function to evaluate the model accuracy\n",
    "def evaluate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            outputs = model(batch_x)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(model, optimizer, criterion, dataloader, num_epochs, title):\n",
    "    train_loss_curve = []\n",
    "    train_accuracy_curve = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the model for one epoch\n",
    "        train_loss = train_epoch(model, dataloader, optimizer, criterion)\n",
    "        train_loss_curve.append(train_loss)\n",
    "\n",
    "        # Evaluate training accuracy\n",
    "        train_accuracy = evaluate_accuracy(model, dataloader)\n",
    "        train_accuracy_curve.append(train_accuracy)\n",
    "\n",
    "    # Plot the training curves\n",
    "    plot_training_curves(train_loss_curve, train_accuracy_curve, title)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "model_2layer = MLP2Layer(input_size, hidden_size, output_size)\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate_stage1 = 0.1\n",
    "learning_rate_stage2 = 0.001\n",
    "batch_size = 32\n",
    "num_epochs_stage1 = 50\n",
    "num_epochs_stage2 = 450\n",
    "\n",
    "# Instantiate the optimizer and loss function\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer_stage1 = optim.SGD(model_2layer.parameters(), lr=learning_rate_stage1)\n",
    "\n",
    "# Create DataLoaders\n",
    "dl_train_2layer = DataLoader(TensorDataset(Xs_train_2d, ys_train_i), batch_size=batch_size, shuffle=True)\n",
    "dl_test_2layer = DataLoader(TensorDataset(Xs_test_2d, ys_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Stage 1 Training\n",
    "model_2layer = train_and_evaluate(model_2layer, optimizer_stage1, criterion, dl_train_2layer, num_epochs_stage1, \"Stage 1\")\n",
    "\n",
    "# Stage 2 Training\n",
    "optimizer_stage2 = optim.SGD(model_2layer.parameters(), lr=learning_rate_stage2)\n",
    "model_2layer = train_and_evaluate(model_2layer, optimizer_stage2, criterion, dl_train_2layer, num_epochs_stage2, \"Stage 2\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = evaluate_accuracy(model_2layer, dl_test_2layer)\n",
    "print(f\"Test Accuracy with 2-layer MLP: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1cf1bb",
   "metadata": {},
   "source": [
    "`Stage 1`\n",
    "\n",
    "**Trining Loss Curve**\n",
    "\n",
    "The loss decreases rapidly during the first epochs, indicating that the model is effectively learning patterns from the data. After about 20 epochs, the loss stabilizes near 0, suggesting that the model has reached a good level of convergence during Stage 1.\n",
    "\n",
    "The convergence speed is high due to the relatively high learning rate (0.1), and there does not appear to be significant overfitting at this stage, as the loss stabilizes without visible oscillations.\n",
    "\n",
    "**Training Accuracy Curve**\n",
    "\n",
    "The accuracy increases rapidly during the first 10 epochs, exceeding 99%. After this threshold, the accuracy stabilizes near 100% for the rest of the stage.\n",
    "\n",
    "This is a sign that the model is highly capable of fitting the training data.\n",
    "\n",
    "`Stage 2`\n",
    "\n",
    "**Trining Loss Curve**\n",
    "\n",
    "During Stage 2, the loss continues to decrease, although very gradually, from around 0.00064 to 0.00058. The decrease is linear and without significant oscillations, which suggests a stable fine-tuning phase.\n",
    "\n",
    "The lower learning rate (0.001) allows the model to refine the parameters without making drastic changes; this further improvement is typical in fine-tuning phases.\n",
    "\n",
    "\n",
    "**Training Accuracy Curve**\n",
    "\n",
    "The accuracy remains fixed at 100% throughout Stage 2, indicating that the model no longer improves on the training set.\n",
    "\n",
    "Stage 2 does not bring improvements in training accuracy, but this is expected: the purpose of fine-tuning is to improve generalization and stability, not necessarily to increase accuracy on the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
