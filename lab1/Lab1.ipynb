{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "354iyEmhWYRc"
   },
   "source": [
    "# Linear Regression in Practice\n",
    "\n",
    "In this lab we will work through an extended example of exploratory data analysis and supervised machine learning using the California Housing Price Dataset. This dataset consists of data about housing characteristics and prices in many districts of the state of California. The **task** this dataset asks us to solve is estimating the median house value in a district from a set of independent housing characteristics.\n",
    "\n",
    "**Note**: the exercises are inline in this notebook and *not* at the end. The exercises will ask you to write some code and sometimes to provide some analysis of your findings in Markdown cells at the end of the exercise.\n",
    "\n",
    "The main objectives of this laboratory are:\n",
    "+ For you to gain familiarity with using Python for numerical programming in Jupyter Notebooks, Google Colaboratory, or *[INSERT TOOL OF CHOICE]*.\n",
    "+ For you to gain familiarity with working with data in Numpy, Pandas, and Scikit-learn.\n",
    "+ For you to learn how to use *visualization* as a tool for understanding the nature of machine learning problems and gain insight into potential solutions.\n",
    "+ To learn to use Scikit-learn to solve simple univariate regression problems and validate your solutions.\n",
    "+ To learn the value of *encapsulation* and *abstraction* of pipeline code for making experiments *reproducible*.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# CODE OF CONDUCT V1.0\n",
    "\n",
    "This Code of Conduct outlines principles for the ethical and transparent use of Large Language Models (LLMs) and existing and internet resources, ensuring integrity and accountability in your laboratory submissions. This first version of the FML Laboratory Code of Conduct was developed in a brainstorming session with **ChatGPT Version 2**, modifying its proposal to the specifics of the FML Laboratories and concentrating on the transparent collaboration with classmates and transparent use of LLMs.\n",
    "\n",
    "#### **1. Transparency in LLM Use**\n",
    "- **Clear Disclosure:** Explicitly state when Large Language Models (LLMs) are used in any part of the process, including data analysis, code generation, or writing.\n",
    "- **Model Limitations:** Acknowledge the inherent limitations of LLMs, such as potential biases, and make clear where human intervention was applied to verify results or to modify/augment produced code.\n",
    "\n",
    "#### **2. Proper Attribution and Documentation**\n",
    "- **Attribution:** Provide appropriate citations and credits for all external resources, including code, data, and models.\n",
    "- **Clear Documentation:** Maintain detailed records of tools, methods, and models used, ensuring transparency and reproducibility in your submitted laboratory solutions.\n",
    "\n",
    "#### **3. Collaboration and Individual Work**\n",
    "- **Sharing Solutions:** While collaboration and discussing ideas with classmates are encouraged, solutions to assignments or projects should be your own. Do not copy or submit work created by others, including code or models, as your own.\n",
    "- **Submission Integrity:** All submitted work must reflect your own understanding and effort. If external tools, LLMs, online resources, or code from your classmates were used, they must be properly documented, but the final submission must be an individual effort.\n",
    "\n",
    "#### **4. Accountability**\n",
    "Non-compliance with these guidelines will be subject to review by the course exam commission, with possible disciplinary actions.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Part 1: Warming Up\n",
    "\n",
    "In this first set of exercises we will analyze our dataset and build a simple linear regression pipeline. This is a fairly typical task that is asked of anyone working with Data Science: Here is some data, do something useful with it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuH_jItJW0x3"
   },
   "source": [
    "### Step 1: Data Modeling\n",
    "\n",
    "OK, let's get started. The first thing we want to do is get our dataset loaded and start to get a feel for it. This is always a good idea -- we *play* with the data first in order to get a better understanding of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JooRxF-EWy_K"
   },
   "outputs": [],
   "source": [
    "# Initial imports -- these are fairly standard.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the function that will download the dataset.\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load the sklearn version of the California Housing dataset.\n",
    "ds = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WafFRz0hXbaj"
   },
   "source": [
    "### Exercise 1a: Poking Around\n",
    "\n",
    "Spend some time looking at the elements of the `ds` we just loaded (it's a python `dict`). Find the description of the dataset and make sure you understand what the features are and what the targets variable is. **Hints**: to get the keys of the dictionary, use: `ds.keys()`.\n",
    "\n",
    "We are going to construct a Pandas `DataFrame` in the next exercise. Where can you get reasonable column names from the sklearn dataset object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "print(ds.keys())\n",
    "print(ds.DESCR)\n",
    "print(ds.data.shape)   \n",
    "print(ds.feature_names)\n",
    "print(ds.target.shape)\n",
    "print(ds.target_names)\n",
    "print(ds.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis**: We have a regression problem (see documentation in 'ds.DESCR') with 8 indipendent input varianles (see names in 'ds.feature_name') ad a single dependent target (see 'ds.target_names'). The dataset contains 20k+ rows pf samples, our goal is to estimate the median house value for California housing distrincts from the given household variables.\n",
    "\n",
    "scrivere ci√≤ che si scopre via via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHk-0p74YvlK"
   },
   "source": [
    "### Exercise 1b: Creating a Pandas DataFrame\n",
    "\n",
    "OK, now we can create the `DataFrame` to hold our independent variables and a `Series` to hold the target values. Make sure you use good column names when constructing the `DataFrame`. Some relevant documentation: [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) and [pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MMFXfX7YAFA"
   },
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame for our dataset and a Pandas Series for the targets.\n",
    "\n",
    "# Your code to build the DataFrame here (replace None)\n",
    "df = pd.DataFrame(data = ds.data, columns = ds.feature_names)\n",
    "print(df)\n",
    "\n",
    "# Your code to build the target Series here (replace None)\n",
    "targets = pd.Series(ds.target)\n",
    "print(targets)\n",
    "\n",
    "#pandas serve per creare delle righe e colonne con i dati che abbiamo dandogli un nome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W45Rdpeuago-"
   },
   "source": [
    "### Exercise 1c: Examining the Data\n",
    "\n",
    "Study the *descriptive statistics* of the data. Do you notice anything \"strange\" about any of the features? Are the features scaled similarly? **Hint**: Use the `.describe()` method on the DataFrame you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis Here** (in Markdown).\n",
    "We do not have any missing values, most features are in the $\\mathcal(0)(1)$ ange, with some several orders of magnitude higher (Population, in particular, is in the $\\mathcal(0)(1000)$ rage). The variance of input features are generally in range with range with their magnitudes, with the exception of AveOccup which has an elevated variance. \n",
    "\n",
    "Non ci sono dati mancanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**: our target variables are distributed reasonably well (at least in the first-and second-order sense), which mean and standard deviation in the same range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftU3jmhwgw2I"
   },
   "source": [
    "---\n",
    "### Step 2: Visualization\n",
    "\n",
    "OK, now that we have a bit of a *feel* for our data, let's get a better idea about it through visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5WZhoeOjeRd"
   },
   "source": [
    "### Exercise 2a: Visualizing the Target\n",
    "Create a plot to study the **distribution** of our target values. The best tool for that is a **histogram**. Search for this functionality in the Matplotlib documentation.\n",
    "\n",
    "**Note**: In addition to *histograms*, try out the Seaborn function `distplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your visualization code here.\n",
    "targets.hist(bins=16, edgecolor='black') #pandas ha un metodo hist che permette di fare un istogramma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mettere un po' di caxzzate\n",
    "**Your Analysis Here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.hist(targets, bins=16, edgecolor='black')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.histplot(targets, bins=16, kde=True, color='lightblue')\n",
    "\n",
    "plt.title('Targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** Kind of a skewed Gaussian shape for our target values, with a long-is tail "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_9GRJSQkhAg"
   },
   "source": [
    "### Exercise 2b: Subplots\n",
    "Now create a multi-plot figure to visualize the distributions of **all** of the independent features in the dataset. Make sure you use `figsize=` to resize the figure appropriately.\n",
    "\n",
    "A few things that will help with this:\n",
    "+ If you want to index columns by **integer** indices, use the `.iloc()` method (e.g. `df.iloc[:,1]`).\n",
    "+ If you extract a column as a `Series` from a `DataFrame`, you can recover its name with the `name` attribute.\n",
    "+ Encapsulate you plotting code in a **function** you can call later.\n",
    "\n",
    "**Super Hint**: Pandas already has this functionality **built-in**. If you can find it, use it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MedInc.hist(bins=50, edgecolor='black') \n",
    "plt.figure(figsize=(10, 8))\n",
    "df.Population.hist(bins=50, edgecolor='black') #pandas ha un metodo hist che permette di fare un istogramma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0stkGgwJkfcS"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for (i, col) in enumerate(df.columns):\n",
    "    plt.subplot(3, 3, i+1)  # plot on grid 3x3\n",
    "    plt.hist(df[col], 30, edgecolor='white', color='lightblue')\n",
    "    plt.title(df[col].name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** We can see a spike at the start or AveBedrms, Population and AveOccup.\n",
    "We can use the Pandas methods or the matplotlib function, the result is pretty similar. \n",
    "\n",
    "Se l'istogramma √® cos√¨ scalato vuol dire che un valore a dx ci sar√† anche in quelli che non si vedono. (mia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** (prof) Several input features are drammatically skewed due to outliers (this is documented in the ds.DESCR). Other more reasonable, with Gaussian or simple binomial distribution (e.g. Latitude and Longitude). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.Longitude, df.Latitude, c=targets, cmap='hot') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** Use covarianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfWcikC8nEbd"
   },
   "source": [
    "\n",
    "---\n",
    "---\n",
    "## Step 3: Split you Data\n",
    "\n",
    "A very important step. Now we will split our `DataFrame` into training and testing splits.\n",
    "\n",
    "### Exercise 3.1: Create a Split\n",
    "Now we need to create our training and testing splits. Read the documentation for `sklearn.model_selection.train_test_split()`. Use this function to create a **training** split with 75% of the data, and a **test** split with 25% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYXhgQhHlDBx"
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into 75-25 train/test split -- replace the [None]*4 with your code.\n",
    "(Xtr, Xte, ytr, yte) = train_test_split(df, targets, test_size=0.25) #tutte le volte io cambio i valori che vado a prendere, per evitare questo si pu√≤ usare un seed\n",
    "\n",
    "print(\"Test Set shape:\", Xte.shape)\n",
    "print(\"Training Set shape:\", Xtr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: *My* convention for data and label matrices is `Xtr, ytr` (training) and `Xte, yte` (testing) because the `X` and `y` helps link the *code* to the *math*. Start developing your own style to help you organize (and eventually share) your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd_imO7rB-ey"
   },
   "source": [
    "### Exercise 3.2: Fit a LinearRegression\n",
    "Finally some machine learning. Study the documentation for `class sklearn.linear_model.LinearRegression`. Then write some code to fit a linear regression model to your **training** split. Try out your model by computing predictions on some data (use the `model.predict()` method).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxFCBMaqAPQh"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## 1. Creare il modello di regressione lineare\n",
    "model = LinearRegression()\n",
    "\n",
    "# 2. Addestrare il modello sui dati di training\n",
    "model.fit(Xtr, ytr)\n",
    "\n",
    "# 3. Fare previsioni sui dati di test\n",
    "y_pred = model.predict(Xte)\n",
    "\n",
    "model.coef_\n",
    "\n",
    "model.intercept_\n",
    "# Stampare le previsioni\n",
    "print(\"Previsioni sui dati di test:\", y_pred)\n",
    "print(\"coef:\", model.coef_)\n",
    "print(\"intercept\", model.intercept_)\n",
    "\n",
    "print(\"sum\", model.coef_ @ Xte.T + model.intercept_) #numpy @ √® il prodotto matriciale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f4EuH5LCzM2"
   },
   "source": [
    "### Exercise 3.3: Evaluate your Model\n",
    "Write some code to compute the root mean-squared error (RMSE) and mean absolute error (MAE) for you model predictions. Try it on both the **test** and **training** splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return (y_true - y_pred).abs().mean()\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(((y_true - y_pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = model.predict(Xtr)\n",
    "preds_test = model.predict(Xte)\n",
    "\n",
    "print(f'MAE on Train: {mae(ytr, preds_train)}')\n",
    "print(f'RMSE on Train: {rmse(ytr, preds_train)}')\n",
    "print(f'MAE on Test: {mae(yte, preds_test)}')\n",
    "print(f'RMSE on Test: {rmse(yte, preds_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis Here**: Why is the performance on the train set different than that on the test split? What if you change the proportion of training to test data in your splits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gTBZCJ7DXBm"
   },
   "source": [
    "### Exercise 3.4: Visualizing the Results\n",
    "Now I want you to write a function that makes a **residual plot** of the data and the model predictions. This plot should show, for each data point, the **signed error** (i.e. y - predicted) of the model prediction. Do you notice any **patterns** in the errors? Can you link this to previous analyses you made? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tlKd0moCllW"
   },
   "outputs": [],
   "source": [
    "(Xtr, Xte, ytr, yte) = train_test_split(df, targets, train_size=0.5)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(Xtr, ytr)\n",
    "\n",
    "\n",
    "def resplot(y, preds):\n",
    "    plt.scatter(preds, preds-y, s=0.3)\n",
    "    plt.title(\"Residual Plot\")  \n",
    "    plt.xlabel(\"Predictions\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "\n",
    "\n",
    "resplot(model.predict(df), targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkyv8K8BGqDf"
   },
   "source": [
    "### Step 4: Repeat.\n",
    "\n",
    "Now you should put all of the pieces together into a repeatable, reproducible pipeline.\n",
    "\n",
    "### Exercise 4: The Pipeline\n",
    "Write a function (or even just code in the cell that calls previously defined functions) that runs an **experiment**:\n",
    "1. Splitting data\n",
    "1. Instantiating the model\n",
    "1. Fitting the model\n",
    "1. Evaluating the model\n",
    "1. (Maybe) Visualizing results\n",
    "\n",
    "Experiment with different splits to see if the results are the same. Try using more or less training data with respect to test data. Observe how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTY5v32hFs8-"
   },
   "outputs": [],
   "source": [
    "# Your pipeline code here.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pipeline(df, targets, train_size=0.75, degree = 1):\n",
    "    \n",
    "    (Xtr, Xte, ytr, yte) = train_test_split(df, targets, test_size=0.25)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(Xtr, ytr)\n",
    "    \n",
    "    preds_tr = model.predict(Xtr)\n",
    "    preds_te = model.predict(Xte)\n",
    "    \n",
    "    rmse_train = np.square(np.subtract(ytr, preds_tr)).mean()\n",
    "    rmse_test = np.square(np.subtract(yte, preds_te)).mean()\n",
    "    mae_train = np.abs(np.subtract(ytr, preds_tr)).mean()\n",
    "    mae_test = np.abs(np.subtract(yte, preds_te)).mean()\n",
    "    \n",
    "    print(f'Train size: {train_size}')\n",
    "    print(f'Degree: {degree}')\n",
    "    print(f'RMSE on train: {rmse_train:.4f}')\n",
    "    print(f'RMSE on test: {rmse_test:.4f}')\n",
    "    print(f'MAE on train: {mae_train:.4f}')\n",
    "    print(f'MAE on test: {mae_test:.4f}')\n",
    "    print('--------')\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(ytr, preds_tr, label='Train Data', alpha=0.5)\n",
    "    plt.scatter(yte, preds_te, label='Test Data', alpha=0.5)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(f'Degree {degree}, Train Size {train_size}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return rmse_train, rmse_test, mae_train, mae_test\n",
    "\n",
    "for train_size in range(1, 10, 2):\n",
    "    train_size /= 10.0  # Convert to a float in the range [0.0, 1.0]\n",
    "    pipeline(df, targets, train_size)\n",
    "    print(\"Train size:\", train_size)\n",
    "    print('--------')\n",
    "\n",
    "\n",
    "#https://www.geeksforgeeks.org/python-mean-squared-error/\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis Here**: Experiment with different splits to see if the results are the same. Try using more or less training data with respect to test data. Observe how the results change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Part 2: Improving our Regressor\n",
    "\n",
    "Now that we have a simple, baseline linear regression result, let's see if we can't improve on it. This is where the real work begins, and where it is **super** important to ensure that the conclusions we draw are *valid*.\n",
    "\n",
    "**Questions**: Are our independent variables *scaled* similarly? Does our model have *high variance* -- that is, if we fit it to a new training sample, does the result vary dramatically?\n",
    "\n",
    "### Exercise 5: Increasing Model Capacity\n",
    "\n",
    "Check out the documentation for `sklearn.preprocessing.PolynomialFeatures`. Map the independent variables onto a **polynomial** basis of variable order. Fit your model using your pipeline from above and observe its behavior for different degree polynomial embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "rmse_train_values = []\n",
    "rmse_test_values = []\n",
    "mae_train_values = []\n",
    "mae_test_values = []\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def variableSizeModels(train_size = 0.75):\n",
    "    for degree in range(1, 4):\n",
    "        \n",
    "        poly = PolynomialFeatures(degree)    # Create PolynomialFeatures instance with the current degree\n",
    "\n",
    "        df_poly = poly.fit_transform(df)   # Apply the PolynomialFeatures instance to the dataframe\n",
    "        \n",
    "        rmse_train, rmse_test, mae_train, mae_test = pipeline(df_poly, targets, train_size=train_size , degree=degree) \n",
    "        \n",
    "        rmse_train_values.append(rmse_train)\n",
    "        rmse_test_values.append(rmse_test)\n",
    "        mae_train_values.append(mae_train)\n",
    "        mae_test_values.append(mae_test)\n",
    "                \n",
    "\n",
    "variableSizeModels()\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cazzate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Hyperparameter Selection and Cross-validation\n",
    "\n",
    "How should we select the correct *degree* for our polynomial basis? Is the performance on the *training* set equal to the performance on the *test* set? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def variableSizeModels2(train_size = 0.75):\n",
    "    \n",
    "    \n",
    "    for degree in range(1, 5):\n",
    "        \n",
    "        poly = PolynomialFeatures(degree)    # Create PolynomialFeatures instance with the current degree\n",
    "\n",
    "        df_poly = poly.fit_transform(df)   # Apply the PolynomialFeatures instance to the dataframe\n",
    "    \n",
    "        (Xtr, Xte, ytr, yte) = train_test_split(df_poly, targets, train_size=train_size)    \n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(Xtr, ytr)\n",
    "        \n",
    "        #----------\n",
    "        # Perform k-fold cross-validation and calculate mean squared error (MSE)\n",
    "        \n",
    "        mse_scores = cross_val_score(model, Xtr, ytr, scoring =  \"neg_mean_squared_error\")\n",
    "        print(\"Current degree:\", degree)\n",
    "        \n",
    "        mse_scores = -mse_scores\n",
    "\n",
    "        for fold, mse in enumerate(mse_scores, 1):\n",
    "            print(f'Fold {fold}: MSE = {mse:.4f}')\n",
    "            \n",
    "        average_mse = np.mean(mse_scores)\n",
    "        print(f'Average MSE: {average_mse:.4f}')\n",
    "        \n",
    "        #---------\n",
    "        \n",
    "        param_grid = {\n",
    "            'fit_intercept': [True, False],\n",
    "        }        \n",
    "        #When fit_intercept is set to True, the model will estimate both the slope (coefficients) and the intercept.\n",
    "        #When fit_intercept is set to False, the model assumes that the intercept is zero.\n",
    "\n",
    "        # class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None,\n",
    "        # refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "        \n",
    "        grid_search = GridSearchCV(model, param_grid, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "        grid_search.fit(Xtr, ytr)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f'Best Hyperparameters:  {best_params}')\n",
    "\n",
    "        # Get the best estimator (model) from the grid search\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluate the best model on the test data\n",
    "        mse = -grid_search.score(Xte, yte)\n",
    "        print(f'Best Model MSE on Test Data: {mse:.4f}')\n",
    "        print('--------')\n",
    "                \n",
    "\n",
    "variableSizeModels2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Final Analysis Here**: Summarize the conclusions you can make about the best hyperparameter settings for this dataset. How do you know your conclusions are supported by the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Part 3: Optional\n",
    "\n",
    "### Exercise 7 (BONUS): Ordinary Least Squares with Gradient Descent\n",
    "This is an *optional* exercise, but I think everyone should implement gradient descent at least once in their life, so if you like a challenge this assignment can earn you up to five (5) bonus points our of 100 on this assignment.\n",
    "\n",
    "#### Exercise 7.1: The Loss Function\n",
    "Recall that the loss function for parameters $\\mathbf{w}$ on dataset $\\mathcal{D} = \\{ (\\mathbf{x}_n, y_n)\\}_{n=1}^{N}$ we use for least squares regression is (assume that the inputs $\\mathbf{x}$ have already been augmented with $x_0 = 1$ to account for the bias parameter $w_0$):\n",
    "$$\n",
    "\\mathcal{L}(\\mathcal{D}, \\mathbf{w}) = \\frac{1}{2} \\sum_{n=1}^{N} (\\mathbf{w}^T \\mathbf{x}_n - y_n)^2\n",
    "$$\n",
    "\n",
    "Start by implementing a function `error(w, Xs, ys)` that computes this loss function. This function should be *independent* of feature dimensionality and **do not use loops**!\n",
    "\n",
    "Test this function using data from the California Housing dataset (after augmenting it with a constant 1 in the first dimension!) with the parmaters $\\mathbf{w}$ set to the solution found by `LinearRegression`. Compare it to randomly initialized $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the error function\n",
    "def error(w, Xs, ys):\n",
    "    # Compute the predictions for all data points\n",
    "    predictions = np.dot(Xs, w)\n",
    "    \n",
    "    # Compute the residuals (predicted - actual values)\n",
    "    residuals = predictions - ys\n",
    "    \n",
    "    # Compute the squared error and take the sum, then divide by 2\n",
    "    loss = 0.5 * np.sum(residuals ** 2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Load California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Add a bias term (column of 1s) to the design matrix X\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Fit the LinearRegression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use only the coefficients (since the bias is included in the X matrix)\n",
    "w_learned = model.coef_\n",
    "\n",
    "# Compute the loss using the learned weights\n",
    "train_loss_learned = error(w_learned, X_train, y_train)\n",
    "test_loss_learned = error(w_learned, X_test, y_test)\n",
    "\n",
    "print(f'Learned weights - Training Loss: {train_loss_learned:.4f}, Test Loss: {test_loss_learned:.4f}')\n",
    "\n",
    "# Compare with randomly initialized weights\n",
    "np.random.seed(42)\n",
    "w_random = np.random.randn(X_train.shape[1])\n",
    "\n",
    "train_loss_random = error(w_random, X_train, y_train)\n",
    "test_loss_random = error(w_random, X_test, y_test)\n",
    "\n",
    "print(f'Random weights - Training Loss: {train_loss_random:.4f}, Test Loss: {test_loss_random:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7.2: The Gradient of the Loss Function\n",
    "Now we need the *gradient* of the loss function in order to improve our solution. Recall that the gradient of the loss is:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\nabla_{\\mathbf{w}} \\mathcal{L}(\\mathcal{D}, \\mathbf{w}) &=& \\nabla_{\\mathbf{w}} \\frac{1}{2} \\sum_{n=1}^{N} (\\mathbf{w}^T \\mathbf{x}_n - y_n)^2 \\\\\n",
    "&=& \\frac{1}{2} \\sum_{n=1}^{N} \\nabla_{\\mathbf{w}} (\\mathbf{w}^T \\mathbf{x}_n - y_n)^2 \\mbox{ (by linearity of the gradient)} \\\\\n",
    "&=& \\sum_{n=1}^{N} (\\mathbf{w}^T \\mathbf{x}_n - y_n) \\nabla_{\\mathbf{w}} (\\mathbf{w}^T \\mathbf{x}_n) \\mbox{ (by gradient rule for quadratics and chain rule)}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "Write a Python function `grad_error(w, Xs, ys)` to compute this gradient of the loss function for a given $\\mathbf{w}$ and dataset $\\mathcal{D}$. Again, if you find yourself writing loops, your probably doing something wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the gradient of the error function\n",
    "def grad_error(w, Xs, ys):\n",
    "    # Compute the residual (predicted - actual values)\n",
    "    residuals = np.dot(Xs, w) - ys\n",
    "    \n",
    "    # Compute the gradient as X^T * residuals\n",
    "    grad = np.dot(Xs.T, residuals)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "# Load California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Add a bias term (column of 1s) to the design matrix X\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Fit the LinearRegression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use only the coefficients (since the bias is included in the X matrix)\n",
    "w_learned = model.coef_\n",
    "\n",
    "# Compute the gradient using the learned weights\n",
    "grad_learned = grad_error(w_learned, X_train, y_train)\n",
    "print(\"Gradient using learned weights:\")\n",
    "print(grad_learned)\n",
    "\n",
    "# Compare with randomly initialized weights\n",
    "np.random.seed(42)\n",
    "w_random = np.random.randn(X_train.shape[1])\n",
    "\n",
    "# Compute the gradient using random weights\n",
    "grad_random = grad_error(w_random, X_train, y_train)\n",
    "print(\"\\nGradient using random weights:\")\n",
    "print(grad_random)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7.3: Gradient Descent\n",
    "Now we have everything we need to, starting from a randomly initialized $\\mathbf{w}$ and some data $\\mathcal{D}$, iteratively improve our solution (up to some numerical tolerance). Recall that our gradient descent update rule is:\n",
    "$$\n",
    "\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\eta \\nabla_{\\mathbf{w}} \\mathcal{L}(\\mathcal{D}, \\mathbf{w}_{t})\n",
    "$$\n",
    "Write a Python function `gradient_descent(w, Xs, ys, eta, tol=1e-5)` to perform gradient descent to convergence (i.e. until the total loss between iterations is less than `tol`). Here you can use a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Gradient of the error function\n",
    "def grad_error(w, Xs, ys):\n",
    "    residuals = np.dot(Xs, w) - ys\n",
    "    grad = np.dot(Xs.T, residuals)\n",
    "    return grad\n",
    "\n",
    "# Error function (loss)\n",
    "def error(w, Xs, ys):\n",
    "    predictions = np.dot(Xs, w)\n",
    "    residuals = predictions - ys\n",
    "    loss = 0.5 * np.sum(residuals ** 2)\n",
    "    return loss\n",
    "\n",
    "# Gradient Descent Algorithm with Gradient Clipping\n",
    "def gradient_descent(w, Xs, ys, eta, tol=1e-5, max_iter=1000, clip_value=100):\n",
    "    prev_loss = error(w, Xs, ys)\n",
    "    for i in range(max_iter):\n",
    "        # Compute the gradient of the loss\n",
    "        grad = grad_error(w, Xs, ys)\n",
    "        \n",
    "        # Clip the gradient to avoid overflow\n",
    "        grad = np.clip(grad, -clip_value, clip_value)\n",
    "        \n",
    "        # Update the weights using the gradient\n",
    "        w = w - eta * grad\n",
    "        \n",
    "        # Compute the new loss\n",
    "        curr_loss = error(w, Xs, ys)\n",
    "        \n",
    "        # Check for convergence (if loss improvement is below tolerance)\n",
    "        if abs(prev_loss - curr_loss) < tol:\n",
    "            print(f'Converged after {i+1} iterations.')\n",
    "            break\n",
    "        \n",
    "        prev_loss = curr_loss\n",
    "\n",
    "    return w\n",
    "\n",
    "# Load California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Add a bias term (column of 1s) to the design matrix X\n",
    "X_scaled = np.hstack([np.ones((X_scaled.shape[0], 1)), X_scaled])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize weights with smaller random values\n",
    "np.random.seed(42)\n",
    "w_random = np.random.randn(X_train.shape[1]) * 0.01  # Smaller initialization\n",
    "\n",
    "# Run gradient descent with a smaller learning rate and gradient clipping\n",
    "learning_rate = 1e-6  # Smaller learning rate\n",
    "w_optimized = gradient_descent(w_random, X_train, y_train, eta=learning_rate)\n",
    "\n",
    "# Output the final optimized weights\n",
    "print(\"Optimized weights from gradient descent:\")\n",
    "print(w_optimized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your implementation of gradient descent to solve the regression problem for the California Housing dataset. You will probably have to play with different learning rates, but verify that you end up with a solution (very) close to the one found by Scikit-learn's `LinearRegression` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Add a bias term (column of 1s) to the design matrix X\n",
    "X_scaled = np.hstack([np.ones((X_scaled.shape[0], 1)), X_scaled])  # Add intercept term\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Implement gradient descent functions\n",
    "def grad_error(w, Xs, ys):\n",
    "    residuals = np.dot(Xs, w) - ys\n",
    "    grad = np.dot(Xs.T, residuals)  # Gradient of the loss function\n",
    "    return grad\n",
    "\n",
    "def error(w, Xs, ys):\n",
    "    predictions = np.dot(Xs, w)\n",
    "    residuals = predictions - ys\n",
    "    loss = 0.5 * np.sum(residuals ** 2)  # Loss function\n",
    "    return loss\n",
    "\n",
    "def gradient_descent(w, Xs, ys, eta, tol=1e-5, max_iter=1000, clip_value=100):\n",
    "    prev_loss = error(w, Xs, ys)\n",
    "    for i in range(max_iter):\n",
    "        # Compute the gradient of the loss\n",
    "        grad = grad_error(w, Xs, ys)\n",
    "        \n",
    "        # Clip the gradient to avoid overflow\n",
    "        grad = np.clip(grad, -clip_value, clip_value)\n",
    "        \n",
    "        # Update the weights using the gradient\n",
    "        w = w - eta * grad\n",
    "        \n",
    "        # Compute the new loss\n",
    "        curr_loss = error(w, Xs, ys)\n",
    "        \n",
    "        # Check for convergence (if loss improvement is below tolerance)\n",
    "        if abs(prev_loss - curr_loss) < tol:\n",
    "            print(f'Converged after {i+1} iterations.')\n",
    "            break\n",
    "        \n",
    "        prev_loss = curr_loss\n",
    "\n",
    "    return w\n",
    "\n",
    "# 1. Scikit-learn's LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the weights from Scikit-learn's LinearRegression\n",
    "w_sklearn = np.hstack([model.intercept_, model.coef_])  # includes intercept\n",
    "print(\"Scikit-learn Linear Regression weights:\")\n",
    "print(w_sklearn)\n",
    "print(f\"Shape of Scikit-learn weights: {w_sklearn.shape}\")\n",
    "\n",
    "# 2. Our Gradient Descent implementation\n",
    "np.random.seed(42)\n",
    "w_random = np.random.randn(X_train.shape[1]) * 0.01  # Initialize with a small random value for all weights (10 weights)\n",
    "\n",
    "# Choose a learning rate\n",
    "learning_rate = 1e-5\n",
    "w_optimized = gradient_descent(w_random, X_train, y_train, eta=learning_rate)\n",
    "\n",
    "print(\"Our Gradient Descent optimized weights:\")\n",
    "print(w_optimized)\n",
    "print(f\"Shape of Optimized weights: {w_optimized.shape}\")\n",
    "\n",
    "# Compare the two sets of weights\n",
    "print(\"Difference between weights:\")\n",
    "try:\n",
    "    print(w_optimized - w_sklearn)\n",
    "except ValueError as e:\n",
    "    print(\"Error during weight comparison:\", e)\n",
    "\n",
    "# Evaluate both models using Mean Squared Error (MSE)\n",
    "y_pred_sklearn = model.predict(X_test)\n",
    "mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "print(f\"Scikit-learn MSE: {mse_sklearn:.4f}\")\n",
    "\n",
    "y_pred_gd = np.dot(X_test, w_optimized)\n",
    "mse_gd = mean_squared_error(y_test, y_pred_gd)\n",
    "print(f\"Gradient Descent MSE: {mse_gd:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Numerical Programming and Reproducible Science.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
